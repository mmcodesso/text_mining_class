{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assigment 04 \n",
    "\n",
    "In this Assigment, we are going to paarse XBRL files and extract some partes of the files.\n",
    "\n",
    "The urls from the files are into a xml files, so we need to parse, find the right tags to get the links\n",
    "\n",
    "In this assigment, insted of saving all files into memory, we will save into disk, extract only the parts we need than save into a dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this version 04.1  I changed the code to extract the tags from XBRL without saving it locally, it will only save our final database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing dependencies\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the list of the files in https://www.sec.gov/structureddata/rss-feeds-submitted-filings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'https://www.sec.gov/Archives/edgar/monthly/xbrlrss-2017-08.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We get the xml file with the links to ours XBRL files \n",
    "xmlfile = requests.get(url).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating empty list to store the data.\n",
    "companies = []\n",
    "urls = []\n",
    "file = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open the xm file to parse and find the url for the xbrl files\n",
    "tree = ET.fromstring(xmlfile)\n",
    "item = tree.findall('channel/item')\n",
    "\n",
    "#The for loop will parse the xml file to find the link to the xbrl files we need\n",
    "for entry in item:   \n",
    "    \n",
    "    desc = entry.findtext('description')  \n",
    "    \n",
    "    if desc == '10-K':\n",
    "        companyName = ''\n",
    "        xbrlurl = ''\n",
    "        for item in entry.iter():\n",
    "\n",
    "            if item.tag == '{http://www.sec.gov/Archives/edgar}companyName':\n",
    "                companyName = item.text\n",
    "                \n",
    "            if item.tag =='{http://www.sec.gov/Archives/edgar}xbrlFiles':\n",
    "                for ite  in item:\n",
    "                    if ite.attrib['{http://www.sec.gov/Archives/edgar}description'] == 'XBRL INSTANCE DOCUMENT':\n",
    "                        xbrlurl = ite.attrib['{http://www.sec.gov/Archives/edgar}url']\n",
    "        \n",
    "        #Some companies dont have the xbrl file we are going to use\n",
    "        if  xbrlurl != '': \n",
    "            companies.append(companyName)  \n",
    "            urls.append(xbrlurl)\n",
    "            file.append(xbrlurl.split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating a Dataframe to easely manipulate the data\n",
    "data = pd.DataFrame(data ={'Company': companies,\n",
    "                           'url': urls,\n",
    "                           'file': file})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a sample of 100 documents\n",
    "data = data.sample(100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Lets create a checkpoint for start here next time\n",
    "data.to_json('./data/10k-xbrl_v2.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing XBRL files\n",
    "\n",
    "Now that we have all files, we need to find only the tags we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"Processing\")\n",
    "\n",
    "#Loading the data\n",
    "data = pd.read_json('./data/10k-xbrl_v2.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xbrl_tag(url,tags=[]):\n",
    "    import xml.etree.ElementTree as ET\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    import unidecode\n",
    "    import re\n",
    "    from nltk.corpus import stopwords\n",
    "\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    text = ''\n",
    "    #xbrlfile = xbrlfile\n",
    "    #tree = ET.parse(xbrlfile)\n",
    "    #root = tree.getroot()\n",
    "    \n",
    "    xbrlfile = requests.get(url).text\n",
    "    root = ET.fromstring(xbrlfile)\n",
    "    #item = tree.findall('channel/item')\n",
    "    \n",
    "    for item in root.findall('.//'):\n",
    "        #Only will get the tag we need\n",
    "        for tag in tags:\n",
    "            if item.tag.find(tag) >= 0:          \n",
    "                text = BeautifulSoup(item.text,\"lxml-xml\",).get_text()\n",
    "                text = unidecode.unidecode(text)\n",
    "                text = re.sub('\\s', ' ',text) \n",
    "                text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "                text = text.lower().split()\n",
    "                text = [w for w in text if not w in stops]\n",
    "                text = \" \".join(text)\n",
    "    return text            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Commitment and Contigencies Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tags = ['CommitmentsAndContingenciesDisclosure', 'ContingenciesDisclosure','CommitmentsDisclosure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 100/100 [00:23<00:00,  5.72it/s]\n"
     ]
    }
   ],
   "source": [
    "data['Comitiment'] = data['url'].progress_apply(xbrl_tag,tags=tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26  companies don't use this tag\n"
     ]
    }
   ],
   "source": [
    "# Show how many companies dont used this tags\n",
    "print(data['Company'][data['Comitiment'].apply(len) == 0].count(), ' companies don\\'t use this tag')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Importing Income Tax Disclosure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 100/100 [00:25<00:00,  5.14it/s]\n"
     ]
    }
   ],
   "source": [
    "tags = ['IncomeTaxDisclosure']\n",
    "data['Income_Tax'] = data['url'].progress_apply(xbrl_tag,tags=tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6  companies don't use this tag\n"
     ]
    }
   ],
   "source": [
    "print(data['Company'][data['Income_Tax'].apply(len) == 0].count(), ' companies don\\'t use this tag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'commitments contingencieslegal proceedingssysco engaged various legal proceedings arisen fully adjudicated likelihood loss legal proceedings based definitions within contingency accounting literature ranges remote reasonably possible probable probable reasonably estimable losses accrued based estimates range potential losses associated matters management believe ultimate resolution proceedings either individually aggregate material adverse effect upon consolidated financial position results operations company however final results legal proceedings cannot predicted certainty company failed prevail one legal matters associated realized losses exceed company current estimates range potential losses company consolidated financial position results operations could materially adversely affected future periods commitmentssysco committed aggregate product purchases resale order benefit centralized approach purchasing majority agreements expire within one year however certain agreements terms fiscal agreements commit company minimum volume various pricing terms including fixed pricing variable pricing combination thereof minimum amounts committed july totaled approximately billion minimum amounts committed year follows amount thousands sysco contracts various third party service providers receive information technology services services committed periods fiscal may extended july total remaining cost services period expected approximately million portion committed amount may reduced sysco utilizing less estimated resources increased sysco utilizing estimated resources certain agreements allow adjustments inflation sysco may also cancel portion services provided subject termination fees decrease time sysco terminate services fiscal estimated termination fees incurred fiscal would approximately million'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preview how the text look\n",
    "data['Comitiment'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Lets create a checkpoint for start here next time\n",
    "data.to_json('./data/10k-xbrl_v2.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with the text\n",
    "\n",
    "Now we can analize the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "\n",
    "#Loading the data\n",
    "data = pd.read_json('./data/10k-xbrl_v2.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Negative words\n",
    "neg_stemmed = []\n",
    "url_neg = 'https://raw.githubusercontent.com/jeffreybreen/twitter-sentiment-analysis-tutorial-201107/08a269765a6b185d5f3dd522c876043ba9628715/data/opinion-lexicon-English/negative-words.txt'\n",
    "neg_words = pd.read_fwf(url_neg,encoding='latin-1',skiprows=34,header=None, \n",
    "                       names=['negatives'])\n",
    "\n",
    "for word in neg_words['negatives']:\n",
    "    neg_stemmed.append(stemmer.stem(word))\n",
    "\n",
    "neg_stemmed = set(neg_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_count(data):\n",
    "    return len(data.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def negative_count (data):\n",
    "    corpus = (\" \".join([stemmer.stem(word) \\\n",
    "                                   for word in data.split()])) \n",
    "    return len([word for word in corpus.split() if word in neg_stemmed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating a new collumn for the Commitiment word count \n",
    "data['Comitiment word count'] = data['Comitiment'].apply(word_count)\n",
    "#Creating a new collumn for the Commitiment Negative word count\n",
    "data['Comitiment Negative words'] = data['Comitiment'].apply(negative_count)\n",
    "#Creating a new collumn for the ratio\n",
    "data['Negative Ratio'] = round(data['Comitiment Negative words'] / data['Comitiment word count'],6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Comitiment word count</th>\n",
       "      <th>Comitiment Negative words</th>\n",
       "      <th>Negative Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>CENTENARY INTERNATIONAL CORP</td>\n",
       "      <td>380</td>\n",
       "      <td>23</td>\n",
       "      <td>0.060526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>GOLDEN EAGLE INTERNATIONAL INC</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>SKYLINE CORP</td>\n",
       "      <td>232</td>\n",
       "      <td>20</td>\n",
       "      <td>0.086207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Fenix Parts, Inc.</td>\n",
       "      <td>954</td>\n",
       "      <td>96</td>\n",
       "      <td>0.100629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>SANFILIPPO JOHN B &amp; SON INC</td>\n",
       "      <td>155</td>\n",
       "      <td>11</td>\n",
       "      <td>0.070968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>PROCTER &amp; GAMBLE Co</td>\n",
       "      <td>298</td>\n",
       "      <td>15</td>\n",
       "      <td>0.050336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>SHARPS COMPLIANCE CORP</td>\n",
       "      <td>121</td>\n",
       "      <td>4</td>\n",
       "      <td>0.033058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>BofI Holding, Inc.</td>\n",
       "      <td>790</td>\n",
       "      <td>78</td>\n",
       "      <td>0.098734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ECOLOCAP SOLUTIONS INC.</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>ELITE GROUP INC.</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Company  Comitiment word count  \\\n",
       "89    CENTENARY INTERNATIONAL CORP                    380   \n",
       "96  GOLDEN EAGLE INTERNATIONAL INC                      0   \n",
       "76                    SKYLINE CORP                    232   \n",
       "67               Fenix Parts, Inc.                    954   \n",
       "44     SANFILIPPO JOHN B & SON INC                    155   \n",
       "88             PROCTER & GAMBLE Co                    298   \n",
       "48          SHARPS COMPLIANCE CORP                    121   \n",
       "41              BofI Holding, Inc.                    790   \n",
       "35         ECOLOCAP SOLUTIONS INC.                     32   \n",
       "61                ELITE GROUP INC.                      3   \n",
       "\n",
       "    Comitiment Negative words  Negative Ratio  \n",
       "89                         23        0.060526  \n",
       "96                          0             NaN  \n",
       "76                         20        0.086207  \n",
       "67                         96        0.100629  \n",
       "44                         11        0.070968  \n",
       "88                         15        0.050336  \n",
       "48                          4        0.033058  \n",
       "41                         78        0.098734  \n",
       "35                          2        0.062500  \n",
       "61                          0        0.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['Company','Comitiment word count','Comitiment Negative words','Negative Ratio']].sample(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "48px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
